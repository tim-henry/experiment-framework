{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/timhenry/Documents/mit/meng/src\")\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import config.input\n",
    "import config.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task, args = \"left_out_varied_location_mnist\", {\n",
    "#         \"test_batch_size\": 1000,\n",
    "#         \"no_cuda\": False,\n",
    "#         \"keep_pcts\": [i / 9 for i in range(1, 10)],\n",
    "#         \"color_indices\": np.arange(9)\n",
    "# }\n",
    "\n",
    "task, args = \"left_out_colored_mnist\", {\n",
    "        \"test_batch_size\": 1000,\n",
    "        \"no_cuda\": False,\n",
    "        \"keep_pcts\": [i / 10 for i in range(1, 11)],\n",
    "        \"color_indices\": np.arange(10)\n",
    "}\n",
    "\n",
    "num_classes = 10\n",
    "model_name = \"resnet\"\n",
    "keep_pct = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader, held_out, control):\n",
    "    label_1_name = test_loader.dataset.class_names[0].capitalize()\n",
    "    label_2_name = test_loader.dataset.class_names[1].capitalize()\n",
    "\n",
    "    model.eval()\n",
    "    num_loss = 0\n",
    "    col_loss = 0\n",
    "    num_correct_count = 0\n",
    "    col_correct_count = 0\n",
    "    correct_count = 0\n",
    "\n",
    "    left_out_num_correct_count = 0\n",
    "    left_out_col_correct_count = 0\n",
    "    left_out_correct_count = 0\n",
    "    left_out_count = 0\n",
    "\n",
    "    non_left_out_num_correct_count = 0\n",
    "    non_left_out_col_correct_count = 0\n",
    "    non_left_out_correct_count = 0\n",
    "    non_left_out_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            num_target, col_target = target[:, 0], target[:, 1]\n",
    "\n",
    "            num_output, col_output = model(data)\n",
    "            num_loss += F.nll_loss(num_output, num_target, reduction='sum').item()\n",
    "            col_loss += F.nll_loss(col_output, col_target, reduction='sum').item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            # get the index of the max log-probability\n",
    "            pred = torch.cat((num_output.argmax(dim=1, keepdim=True), col_output.argmax(dim=1, keepdim=True)), 1)\n",
    "            num_correct, col_correct = pred.eq(target.view_as(pred))[:, 0], pred.eq(target.view_as(pred))[:, 1]\n",
    "            correct = num_correct * col_correct  # both must be correct\n",
    "\n",
    "            num_correct_count += num_correct.sum().item()\n",
    "            col_correct_count += col_correct.sum().item()\n",
    "            correct_count += correct.sum().item()\n",
    "\n",
    "            # Calculate left-out accuracy\n",
    "            mask = np.zeros(num_target.size())\n",
    "            for pair in held_out:\n",
    "                diff_array = np.absolute(target.cpu().numpy() - np.array(pair))\n",
    "                mask = np.logical_or(mask, diff_array.sum(axis=1) == 0)\n",
    "\n",
    "            mask = torch.Tensor(mask.astype(\"uint8\")).byte().to(device)\n",
    "\n",
    "            left_out_num_correct = num_correct * mask\n",
    "            left_out_col_correct = col_correct * mask\n",
    "            left_out_correct = left_out_num_correct * left_out_col_correct\n",
    "\n",
    "            left_out_num_correct_count += left_out_num_correct.sum().item()\n",
    "            left_out_col_correct_count += left_out_col_correct.sum().item()\n",
    "            left_out_correct_count += left_out_correct.sum().item()\n",
    "            left_out_count += mask.sum().item()\n",
    "\n",
    "            # Calculate non_left-out accuracy\n",
    "            mask = np.zeros(num_target.size())\n",
    "            for pair in control:\n",
    "                diff_array = np.absolute(target.cpu().numpy() - np.array(pair))\n",
    "                mask = np.logical_or(mask, diff_array.sum(axis=1) == 0)\n",
    "\n",
    "            mask = torch.Tensor(mask.astype(\"uint8\")).byte().to(device)\n",
    "\n",
    "            non_left_out_num_correct = num_correct * mask\n",
    "            non_left_out_col_correct = col_correct * mask\n",
    "            non_left_out_correct = non_left_out_num_correct * non_left_out_col_correct\n",
    "\n",
    "            non_left_out_num_correct_count += non_left_out_num_correct.sum().item()\n",
    "            non_left_out_col_correct_count += non_left_out_col_correct.sum().item()\n",
    "            non_left_out_correct_count += non_left_out_correct.sum().item()\n",
    "            non_left_out_count += mask.sum().item()\n",
    "\n",
    "    total_loss = num_loss + col_loss\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "          '({} Accuracy: {}/{} ({:.0f}%), {} Accuracy: {}/{} ({:.0f}%))\\n'.format(\n",
    "        total_loss,\n",
    "        correct_count, len(test_loader.dataset), 100. * correct_count / len(test_loader.dataset),\n",
    "        label_1_name, num_correct_count, len(test_loader.dataset), 100. * num_correct_count / len(test_loader.dataset),\n",
    "        label_2_name, col_correct_count, len(test_loader.dataset), 100. * col_correct_count / len(test_loader.dataset)\n",
    "    ))\n",
    "\n",
    "    left_out_acc = None\n",
    "    if left_out_count > 0:\n",
    "        print('Left-Out Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "              '(Left-Out {} Accuracy: {}/{} ({:.0f}%), Left-Out {} Accuracy: {}/{} ({:.0f}%))\\n'.format(\n",
    "            left_out_correct_count, left_out_count, 100. * left_out_correct_count / left_out_count,\n",
    "            label_1_name, left_out_num_correct_count, left_out_count, 100. * left_out_num_correct_count / left_out_count,\n",
    "            label_2_name, left_out_col_correct_count, left_out_count, 100. * left_out_col_correct_count / left_out_count\n",
    "        ))\n",
    "        left_out_acc = left_out_correct_count / left_out_count\n",
    "\n",
    "    non_left_out_acc = None\n",
    "    if non_left_out_count > 0:\n",
    "        print('non_left-Out Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "              '(non_left-Out {} Accuracy: {}/{} ({:.0f}%), non_left-Out {} Accuracy: {}/{} ({:.0f}%))\\n'.format(\n",
    "            non_left_out_correct_count, non_left_out_count, 100. * non_left_out_correct_count / non_left_out_count,\n",
    "            label_1_name, non_left_out_num_correct_count, non_left_out_count,\n",
    "                                                            100. * non_left_out_num_correct_count / non_left_out_count,\n",
    "            label_2_name, non_left_out_col_correct_count, non_left_out_count,\n",
    "                                                            100. * non_left_out_col_correct_count / non_left_out_count\n",
    "        ))\n",
    "        non_left_out_acc = non_left_out_correct_count / non_left_out_count\n",
    "\n",
    "    return {\n",
    "        \"class_1_name\": test_loader.dataset.class_names[0],\n",
    "        \"class_2_name\": test_loader.dataset.class_names[1],\n",
    "        \"num_acc\": num_correct_count / len(test_loader.dataset),\n",
    "        \"col_acc\": col_correct_count / len(test_loader.dataset),\n",
    "        \"acc\": correct_count / len(test_loader.dataset),\n",
    "        \"left_out_num_acc\": left_out_num_correct_count / left_out_count if left_out_count != 0 else None,\n",
    "        \"left_out_col_acc\": left_out_col_correct_count / left_out_count if left_out_count != 0 else None,\n",
    "        \"left_out_acc\": left_out_acc if left_out_count != 0 else None,\n",
    "        \"non_left_out_num_acc\": non_left_out_num_correct_count / non_left_out_count if non_left_out_count != 0 else None,\n",
    "        \"non_left_out_col_acc\": non_left_out_col_correct_count / non_left_out_count if non_left_out_count != 0 else None,\n",
    "        \"non_left_out_acc\": non_left_out_acc if non_left_out_count != 0 else None,\n",
    "        \"num_loss\": num_loss,\n",
    "        \"col_loss\": col_loss,\n",
    "        \"loss\": total_loss\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (fc2_number): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (fc2_color): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model function\n",
    "state_dict_directory = \"analysis/state_dicts/\" + task + \"/\" + model_name + \"/\"\n",
    "model = config.model.options[model_name](num_classes)\n",
    "state_dict = torch.load(state_dict_directory + str(keep_pct) + \".pt\", map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda?  False\n"
     ]
    }
   ],
   "source": [
    "args['use_cuda'] = not args['no_cuda'] and torch.cuda.is_available()\n",
    "print(\"use_cuda? \", args['use_cuda'])\n",
    "device = torch.device(\"cuda\" if args['use_cuda'] else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/usr/local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1289.6602, Accuracy: 9652/10000 (97%)\n",
      "(Shape Accuracy: 9725/10000 (97%), Color Accuracy: 9925/10000 (99%))\n",
      "\n",
      "Left-Out Accuracy: 860/1032 (83%)\n",
      "(Left-Out Shape Accuracy: 898/1032 (87%), Left-Out Color Accuracy: 992/1032 (96%))\n",
      "\n",
      "non_left-Out Accuracy: 981/1003 (98%)\n",
      "(non_left-Out Shape Accuracy: 984/1003 (98%), non_left-Out Color Accuracy: 1000/1003 (100%))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, test_loader_fn = config.input.options[task]\n",
    "test_loader = test_loader_fn(args)\n",
    "\n",
    "test_results = {}\n",
    "test_results[keep_pct] = [test(\n",
    "    args, model, device, test_loader, test_loader.dataset.held_out, test_loader.dataset.control\n",
    ")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
